import numpy as np

class ClimbNeuralNetwork:
    convW1 = np.zeros(32)
    convW2 = []
    def forward(self):

        # 3x224x224 input
        # Conv layer 32x3x3x3
        # 32x222x222 output
        # ReLU activation function
        # Max pooling
        # 32x111x111
        # Conv layer 64x32x3x3
        # 64x109x109
        # ReLU activation function
        # Max pooling
        # 64x54x54
        # flatten = 186624
        # ReLU activation
    def backprop(self):


        return True